{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Data Wrangling\n",
    "\n",
    "This is a demonstration of data wrangling using [Pandas](https://pandas.pydata.org/) the library for data analysis and manipulation.\n",
    "\n",
    "This Jupyter Notepad demonstrates different processes you can apply to your data to prepare it for feature engineering and model training. For this demonstration we will wrangle the diabetes data set you previewed in the last Jupyter Notebook.\n",
    "\n",
    "> [!Note]\n",
    "> None of these processes are destructive to the source CSV as long as you save the modified data to a new CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.1.2.diabeties_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The `isnull().sum()` method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "51c68e9f-70f9-4d87-8403-e2fd10054ef4",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "1"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       1\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have null data there are many ways to deal with the empty/null values. These are the two most common approaches.\n",
    "1. Remove any row with a null value with a `dropna()` method call.\n",
    "2. Replace missing values with another value with a `fillna()` method call. Generally, we use mean value for numerical columns because it may cause minimal changes in your mathematical analysis while maintaining the original size of the data.\n",
    "\n",
    "Students should reflect why this example removes the null 'SEX' but replacing the mean 'Target'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "060d7cf9-3d34-416c-ba82-fb9f866281fb",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "0"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values\n",
    "data_frame = data_frame.dropna(subset=['SEX'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e69812ac-884f-40cd-b358-230386710229",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "0"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Null values with the mean value for the column\n",
    "data_frame['Target'] = data_frame['Target'].fillna(data_frame['Target'].mean())\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Duplicate data can have detrimental effects on your machine learning models and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or biased models.\n",
    "\n",
    "The `duplicated().sum()` method call returns the count of duplicate rows in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data\n",
    "\n",
    "We can run a lambda function on a column to modify its values. For a simple example, letâ€™s convert the Sex to lowercase. To run a function over a complete column, we can use the apply method which iterates over each row and modifies the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e38735af-e7bf-4f7b-9766-831e43e7f6a4",
       "rows": [
        [
         "0",
         "female"
        ],
        [
         "1",
         "female"
        ],
        [
         "2",
         "male"
        ],
        [
         "3",
         "male"
        ],
        [
         "4",
         "male"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    female\n",
       "1    female\n",
       "2      male\n",
       "3      male\n",
       "4      male\n",
       "Name: SEX, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda x: x.lower())\n",
    "data_frame['SEX'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that there are no data entry errors by the `unique()` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male', 'girl'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda gender: 'male' if gender.lower() == 'male' else 'female')\n",
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "Outliers can skew your analysis on numerical columns, and it is important to remove them. We can use the 25th and 75th quartile on numerical data, to get the inter-quartile range. This allows us to estimate an acceptable range, and we can then filter out any values outside this range. Mathematically, outliers are values occurring outside 1.5 times the interquartile range (IQR) from the first quartile (Q1) or third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    448.000000\n",
      "mean      91.234375\n",
      "std       11.453865\n",
      "min       58.000000\n",
      "25%       83.000000\n",
      "50%       91.000000\n",
      "75%       98.000000\n",
      "max      124.000000\n",
      "Name: BGU, dtype: float64\n",
      "Outliers are a BGU above 120.5 or below 60.5\n"
     ]
    }
   ],
   "source": [
    "#get the inter-quartile range on the salary column\n",
    "print(data_frame['BGU'].describe())\n",
    "Q1 = data_frame['BGU'].quantile(0.25)\n",
    "Q3 = data_frame['BGU'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BGU above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    439.000000\n",
      "mean      91.013667\n",
      "std       10.617888\n",
      "min       66.000000\n",
      "25%       83.500000\n",
      "50%       91.000000\n",
      "75%       98.000000\n",
      "max      120.000000\n",
      "Name: BGU, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter salaries within the acceptable range\n",
    "data_frame = data_frame[(data_frame['BGU'] >= Q1 - 1.5 * IQR) & (data_frame['BGU'] <= Q3 + 1.5 * IQR)]\n",
    "print(data_frame['BGU'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range\n",
    "\n",
    "Scaling the features makes it easier for machine learning algorithms to find the optimal solution, as the different scales of the features do not influence them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BGU",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FDR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d046c2ae-255d-4eab-92d3-a2ab378927d2",
       "rows": [
        [
         "count",
         "439.0",
         "439.0",
         "439.0",
         "439.0",
         "439.0",
         "438.0"
        ],
        [
         "mean",
         "26.29749430523918",
         "94.62562642369019",
         "4.056469248291572",
         "0.5126708428246013",
         "1.0683371298405466",
         "149.93150684931507"
        ],
        [
         "std",
         "4.395095659172619",
         "13.984859442037548",
         "1.2698533221079558",
         "0.13272359601017633",
         "0.835772529879045",
         "76.56570061566529"
        ],
        [
         "min",
         "18.0",
         "51.0",
         "2.0",
         "0.2",
         "0.0",
         "25.0"
        ],
        [
         "25%",
         "23.15",
         "84.0",
         "3.0",
         "0.41874999999999996",
         "0.0",
         "85.0"
        ],
        [
         "50%",
         "25.7",
         "93.0",
         "4.0",
         "0.5125",
         "1.0",
         "138.5"
        ],
        [
         "75%",
         "29.2",
         "105.0",
         "5.0",
         "0.6",
         "2.0",
         "206.0"
        ],
        [
         "max",
         "42.2",
         "141.0",
         "9.09",
         "0.875",
         "3.0",
         "346.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>TC</th>\n",
       "      <th>BGU</th>\n",
       "      <th>FDR</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.297494</td>\n",
       "      <td>94.625626</td>\n",
       "      <td>4.056469</td>\n",
       "      <td>0.512671</td>\n",
       "      <td>1.068337</td>\n",
       "      <td>149.931507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.395096</td>\n",
       "      <td>13.984859</td>\n",
       "      <td>1.269853</td>\n",
       "      <td>0.132724</td>\n",
       "      <td>0.835773</td>\n",
       "      <td>76.565701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.700000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>138.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.200000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.200000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BMI          BP          TC         BGU         FDR      Target\n",
       "count  439.000000  439.000000  439.000000  439.000000  439.000000  438.000000\n",
       "mean    26.297494   94.625626    4.056469    0.512671    1.068337  149.931507\n",
       "std      4.395096   13.984859    1.269853    0.132724    0.835773   76.565701\n",
       "min     18.000000   51.000000    2.000000    0.200000    0.000000   25.000000\n",
       "25%     23.150000   84.000000    3.000000    0.418750    0.000000   85.000000\n",
       "50%     25.700000   93.000000    4.000000    0.512500    1.000000  138.500000\n",
       "75%     29.200000  105.000000    5.000000    0.600000    2.000000  206.000000\n",
       "max     42.200000  141.000000    9.090000    0.875000    3.000000  346.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_feature = 'BGU'\n",
    "\n",
    "#the minimum value with space for outliers\n",
    "MIN_BMI = 50\n",
    "\n",
    "#the maximum value with space for outliers\n",
    "MAX_BMI = 130\n",
    "\n",
    "#scale features\n",
    "data_frame[scale_feature] = [(X - MIN_BMI) / (MAX_BMI - MIN_BMI) for X in data_frame[scale_feature]]\n",
    "\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!important]\n",
    "> You need to save the calculations for each dataset you scale for scaling new values for prediction. Use [2.1.2.data.records.md](2.1.2.data.records.md) to record this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.2.Feature_Engineering/2.2.1.wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
